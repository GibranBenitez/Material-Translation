# Material-Translation
The field of Neural Style Transfer (NST) has led to interesting applications that enable to transform the reality as human beings perceive. Particularly, NST for material translation aims to change the material of an object (content) to the target material from a different image (style). Since the style comes from an object of the target material, the synthesized image quality totally depends on the chosen image. Therefore, we propose a material translation method based on NST with an automatic style image retrieval. The proposed CNN-feature-based image retrieval aims to find the ideal style that better translates the material of an object. An ideal style image must share semantic information with the content object, while containing distinctive characteristics of the desired material. Thus, we refine the search by selecting the most discriminative images from the target material, while focusing on the object semantics by removing its style information. To translate materials to object regions, we combine a real-time material segmentation method with NST. In this way, the material of the retrieved style image is transferred to the segmented areas only. We evaluate our proposal with different state-of-the-art NST methods, including conventional and recently proposed approaches. Furthermore, with a human perceptual study applied to 100 participants, we demonstrate that synthesized images of stone, wood, and metal can be perceived as real, even over legit photographs from such materials.  
